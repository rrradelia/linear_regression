{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c753c-8983-4774-ac5e-ab4b722162d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MultiVariable:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_mean = np.mean(X, axis=0)\n",
    "        self.X_std = np.std(X, axis=0)\n",
    "        self.y_mean = np.mean(y)\n",
    "        self.y_std = np.std(y)\n",
    "        self.X = (X - self.X_mean) / self.X_std\n",
    "        self.X = np.hstack((np.ones((self.X.shape[0], 1)), self.X))\n",
    "        self.y = (y - self.y_mean) / self.y_std\n",
    "        self.weights = np.zeros(self.X.shape[1])\n",
    "        self.learning_rate = 0.001\n",
    "        self.max_steps = 1000\n",
    "        self.convergence_threshold = 1e-6\n",
    "        self.round = None\n",
    "        self.batch_size = 10\n",
    "        self.n = X.shape[1]\n",
    "        self.x_symbols = sp.symbols('x:{}'.format(self.n))\n",
    "\n",
    "    def SoSR(self, weights = None):\n",
    "        if weights is None:\n",
    "            weights = self.weights\n",
    "        SoSR = np.square(self.y - (weights @ self.X.T))\n",
    "        return np.sum(SoSR)\n",
    "    \n",
    "    def gradient(self, X = None, y = None):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "        return -2 * X.T @ (y - (self.weights @ X.T))\n",
    "\n",
    "    def GradientDescent(self):\n",
    "        print(\"\\033[1mGradient Descent:\\033[0m\")\n",
    "        losses = []\n",
    "        prev_loss = 0\n",
    "        for i in range(self.max_steps):\n",
    "            weights_gradient = self.gradient()\n",
    "            weights_temp = self.weights - self.learning_rate * weights_gradient\n",
    "            loss = self.SoSR(weights_temp)\n",
    "            losses.append(loss)\n",
    "            if abs(loss - prev_loss) < self.convergence_threshold:\n",
    "                print(\"Converged at iteration\", i)\n",
    "                break\n",
    "            self.weights = weights_temp\n",
    "            prev_loss = loss  \n",
    "\n",
    "        self.show(losses)\n",
    "\n",
    "    def MiniBatchGradientDescent(self):\n",
    "        print(\"\\033[1mMini-Batch Gradient Descent:\\033[0m\")\n",
    "        losses = []\n",
    "        prev_loss = 0\n",
    "        for i in range(self.max_steps):\n",
    "            for j in range(0, len(self.X), self.batch_size):\n",
    "                X_batch = self.X[j : j + self.batch_size, : ]\n",
    "                y_batch = self.y[j : j + self.batch_size]\n",
    "                weights_gradient = self.gradient(X_batch, y_batch)\n",
    "                weights_temp = self.weights - self.learning_rate * weights_gradient\n",
    "                loss = self.SoSR(weights_temp)\n",
    "                losses.append(loss)\n",
    "                self.weights = weights_temp\n",
    "\n",
    "            if abs(loss - prev_loss) < self.convergence_threshold:\n",
    "                print(\"Converged at iteration\", i)\n",
    "                break\n",
    "            prev_loss = loss\n",
    "\n",
    "        self.show(losses)\n",
    "\n",
    "    def StochasticGradientDescent(self):\n",
    "        print(\"\\033[1mStochastic Gradient Descent:\\033[0m\")\n",
    "        losses = []\n",
    "        prev_loss = 0\n",
    "        for i in range(self.max_steps):\n",
    "            for j in range(len(self.X)):\n",
    "                x_point = self.X[j, :]\n",
    "                y_point = self.y[j]\n",
    "                weights_gradient = self.gradient(x_point[np.newaxis, :], np.array([y_point]))\n",
    "                weights_temp = self.weights - self.learning_rate * weights_gradient\n",
    "                loss = self.SoSR(weights_temp)\n",
    "                losses.append(loss)\n",
    "                self.weights = weights_temp\n",
    "\n",
    "            if abs(loss - prev_loss) < self.convergence_threshold:\n",
    "                print(\"Converged at iteration\", i)\n",
    "                break\n",
    "            prev_loss = loss\n",
    "\n",
    "        self.show(losses)\n",
    "\n",
    "    def calculatePlaneEquation(self):\n",
    "        weights = self.weights\n",
    "        def plane_eq(x, y):\n",
    "            return weights[0] + weights[1] * x + weights[2] * y\n",
    "        return plane_eq\n",
    "\n",
    "    def printEquation(self):\n",
    "        weights = self.weights[1:] \n",
    "        bias = self.weights[0] \n",
    "        equation = bias\n",
    "        for i in range(len(weights)):\n",
    "            equation += weights[i] * (self.x_symbols[i] - self.X_mean[i]) / self.X_std[i]\n",
    "        equation_expr = sum([w * (x - m) / s for w, x, m, s in zip(weights, self.x_symbols, self.X_mean, self.X_std)]) + bias\n",
    "        equation_expr = sp.expand(equation_expr) * self.y_std + self.y_mean\n",
    "        equation_expr_rounded = sp.nsimplify(equation_expr, rational=True).evalf()\n",
    "        rounded_equation = sp.N(equation_expr_rounded, self.round) if self.round is not None else equation_expr_rounded\n",
    "        print(sp.pretty(rounded_equation))\n",
    "\n",
    "    def plotLoss(self, losses):\n",
    "        plt.figure(figsize = (9, 6)) \n",
    "        plt.plot(range(len(losses)), losses, label = 'Loss function')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_aspect('auto', adjustable = 'box')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plotResult(self, plane_equation):\n",
    "        if self.X.shape[1] > 3:\n",
    "            print(\"Plotting is supported only for data with up to three features.\")\n",
    "            return\n",
    "\n",
    "        fig = plt.figure(figsize=(7, 7))\n",
    "        ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "        ax.scatter(self.X[:, 1], self.X[:, 2], self.y, c = self.y, cmap = 'viridis')\n",
    "\n",
    "        xmin, xmax = np.min(self.X[:, 1]), np.max(self.X[:, 1])\n",
    "        ymin, ymax = np.min(self.X[:, 2]), np.max(self.X[:, 2])\n",
    "        xx, yy = np.meshgrid(np.linspace(xmin, xmax, 10), np.linspace(ymin, ymax, 10))\n",
    "        \n",
    "        zz = plane_equation(xx, yy)\n",
    "        \n",
    "        ax.plot_surface(xx, yy, zz, alpha = 0.5, cmap = 'viridis')\n",
    "\n",
    "        ax.set_xlabel('X1')\n",
    "        ax.set_ylabel('X2')\n",
    "        ax.set_zlabel('Y')\n",
    "        ax.set_title('Data and Regression Plane')\n",
    "        plt.show()\n",
    "\n",
    "    def show(self, losses):\n",
    "        self.printEquation()\n",
    "        plane_equation = self.calculatePlaneEquation()\n",
    "        self.plotResult(plane_equation)\n",
    "        self.plotLoss(losses)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
